usage: facefusion.py run [-h] [--config-path CONFIG_PATH]
                         [--temp-path TEMP_PATH] [--jobs-path JOBS_PATH]
                         [-s SOURCE_PATHS [SOURCE_PATHS ...]] [-t TARGET_PATH]
                         [-o OUTPUT_PATH]
                         [--face-detector-model {many,retinaface,scrfd,yolo_face,yunet}]
                         [--face-detector-size {640x640}]
                         [--face-detector-margin FACE_DETECTOR_MARGIN [FACE_DETECTOR_MARGIN ...]]
                         [--face-detector-angles FACE_DETECTOR_ANGLES [FACE_DETECTOR_ANGLES ...]]
                         [--face-detector-score [0.0..1.0:0.05]]
                         [--face-landmarker-model {many,2dfan4,peppa_wutz}]
                         [--face-landmarker-score [0.0..1.0:0.05]]
                         [--face-selector-mode {many,one,reference}]
                         [--face-selector-order {left-right,right-left,top-bottom,bottom-top,small-large,large-small,best-worst,worst-best}]
                         [--face-selector-age-start [0..100:1]]
                         [--face-selector-age-end [0..100:1]]
                         [--face-selector-gender {female,male}]
                         [--face-selector-race {white,black,latino,asian,indian,arabic}]
                         [--reference-face-position REFERENCE_FACE_POSITION]
                         [--reference-face-distance [0.0..1.0:0.05]]
                         [--reference-frame-number REFERENCE_FRAME_NUMBER]
                         [--face-occluder-model {many,xseg_1,xseg_2,xseg_3}]
                         [--face-parser-model {bisenet_resnet_18,bisenet_resnet_34}]
                         [--face-mask-types FACE_MASK_TYPES [FACE_MASK_TYPES ...]]
                         [--face-mask-areas FACE_MASK_AREAS [FACE_MASK_AREAS ...]]
                         [--face-mask-regions FACE_MASK_REGIONS [FACE_MASK_REGIONS ...]]
                         [--face-mask-blur [0.0..1.0:0.05]]
                         [--face-mask-padding FACE_MASK_PADDING [FACE_MASK_PADDING ...]]
                         [--voice-extractor-model {kim_vocal_1,kim_vocal_2,uvr_mdxnet}]
                         [--trim-frame-start TRIM_FRAME_START]
                         [--trim-frame-end TRIM_FRAME_END]
                         [--temp-frame-format {bmp,jpeg,png,tiff}]
                         [--keep-temp] [--output-image-quality [0..100:1]]
                         [--output-image-scale {0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,2.25,2.5,2.75,3.0,3.25,3.5,3.75,4.0,4.25,4.5,4.75,5.0,5.25,5.5,5.75,6.0,6.25,6.5,6.75,7.0,7.25,7.5,7.75,8.0}]
                         [--output-audio-encoder {flac,aac,libmp3lame,libopus,libvorbis,pcm_s16le,pcm_s32le}]
                         [--output-audio-quality [0..100:1]]
                         [--output-audio-volume [0..100:1]]
                         [--output-video-encoder {libx264,libx264rgb,libx265,libvpx-vp9,h264_amf,h264_nvenc,hevc_nvenc,h264_qsv,hevc_amf,hevc_qsv,rawvideo}]
                         [--output-video-preset {ultrafast,superfast,veryfast,faster,fast,medium,slow,slower,veryslow}]
                         [--output-video-quality [0..100:1]]
                         [--output-video-scale {0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,2.25,2.5,2.75,3.0,3.25,3.5,3.75,4.0,4.25,4.5,4.75,5.0,5.25,5.5,5.75,6.0,6.25,6.5,6.75,7.0,7.25,7.5,7.75,8.0}]
                         [--output-video-fps OUTPUT_VIDEO_FPS]
                         [--processors PROCESSORS [PROCESSORS ...]]
                         [--age-modifier-model {styleganex_age}]
                         [--age-modifier-direction [-100..100:1]]
                         [--background-remover-model {ben_2,birefnet_general,birefnet_portrait,isnet_general,modnet,ormbg,rmbg_1.4,rmbg_2.0,silueta,u2net_cloth,u2net_general,u2net_human,u2netp}]
                         [--background-remover-color BACKGROUND_REMOVER_COLOR [BACKGROUND_REMOVER_COLOR ...]]
                         [--deep-swapper-model {druuzil/adam_levine_320,druuzil/adrianne_palicki_384,druuzil/agnetha_falskog_224,druuzil/alan_ritchson_320,druuzil/alicia_vikander_320,druuzil/amber_midthunder_320,druuzil/andras_arato_384,druuzil/andrew_tate_320,druuzil/angelina_jolie_384,druuzil/anne_hathaway_320,druuzil/anya_chalotra_320,druuzil/arnold_schwarzenegger_320,druuzil/benjamin_affleck_320,druuzil/benjamin_stiller_384,druuzil/bradley_pitt_224,druuzil/brie_larson_384,druuzil/bruce_campbell_384,druuzil/bryan_cranston_320,druuzil/catherine_blanchett_352,druuzil/christian_bale_320,druuzil/christopher_hemsworth_320,druuzil/christoph_waltz_384,druuzil/cillian_murphy_320,druuzil/cobie_smulders_256,druuzil/dwayne_johnson_384,druuzil/edward_norton_320,druuzil/elisabeth_shue_320,druuzil/elizabeth_olsen_384,druuzil/elon_musk_320,druuzil/emily_blunt_320,druuzil/emma_stone_384,druuzil/emma_watson_320,druuzil/erin_moriarty_384,druuzil/eva_green_320,druuzil/ewan_mcgregor_320,druuzil/florence_pugh_320,druuzil/freya_allan_320,druuzil/gary_cole_224,druuzil/gigi_hadid_224,druuzil/harrison_ford_384,druuzil/hayden_christensen_320,druuzil/heath_ledger_320,druuzil/henry_cavill_448,druuzil/hugh_jackman_384,druuzil/idris_elba_320,druuzil/jack_nicholson_320,druuzil/james_carrey_384,druuzil/james_mcavoy_320,druuzil/james_varney_320,druuzil/jason_momoa_320,druuzil/jason_statham_320,druuzil/jennifer_connelly_384,druuzil/jimmy_donaldson_320,druuzil/jordan_peterson_384,druuzil/karl_urban_224,druuzil/kate_beckinsale_384,druuzil/laurence_fishburne_384,druuzil/lili_reinhart_320,druuzil/luke_evans_384,druuzil/mads_mikkelsen_384,druuzil/mary_winstead_320,druuzil/margaret_qualley_384,druuzil/melina_juergens_320,druuzil/michael_fassbender_320,druuzil/michael_fox_320,druuzil/millie_bobby_brown_320,druuzil/morgan_freeman_320,druuzil/patrick_stewart_224,druuzil/rachel_weisz_384,druuzil/rebecca_ferguson_320,druuzil/scarlett_johansson_320,druuzil/shannen_doherty_384,druuzil/seth_macfarlane_384,druuzil/thomas_cruise_320,druuzil/thomas_hanks_384,druuzil/william_murray_384,druuzil/zoe_saldana_384,edel/emma_roberts_224,edel/ivanka_trump_224,edel/lize_dzjabrailova_224,edel/sidney_sweeney_224,edel/winona_ryder_224,iperov/alexandra_daddario_224,iperov/alexei_navalny_224,iperov/amber_heard_224,iperov/dilraba_dilmurat_224,iperov/elon_musk_224,iperov/emilia_clarke_224,iperov/emma_watson_224,iperov/erin_moriarty_224,iperov/jackie_chan_224,iperov/james_carrey_224,iperov/jason_statham_320,iperov/keanu_reeves_320,iperov/margot_robbie_224,iperov/natalie_dormer_224,iperov/nicolas_coppola_224,iperov/robert_downey_224,iperov/rowan_atkinson_224,iperov/ryan_reynolds_224,iperov/scarlett_johansson_224,iperov/sylvester_stallone_224,iperov/thomas_cruise_224,iperov/thomas_holland_224,iperov/vin_diesel_224,iperov/vladimir_putin_224,jen/angelica_trae_288,jen/ella_freya_224,jen/emma_myers_320,jen/evie_pickerill_224,jen/kang_hyewon_320,jen/maddie_mead_224,jen/nicole_turnbull_288,mats/alica_schmidt_320,mats/ashley_alexiss_224,mats/billie_eilish_224,mats/brie_larson_224,mats/cara_delevingne_224,mats/carolin_kebekus_224,mats/chelsea_clinton_224,mats/claire_boucher_224,mats/corinna_kopf_224,mats/florence_pugh_224,mats/hillary_clinton_224,mats/jenna_fischer_224,mats/kim_jisoo_320,mats/mica_suarez_320,mats/shailene_woodley_224,mats/shraddha_kapoor_320,mats/yu_jimin_352,rumateus/alison_brie_224,rumateus/amber_heard_224,rumateus/angelina_jolie_224,rumateus/aubrey_plaza_224,rumateus/bridget_regan_224,rumateus/cobie_smulders_224,rumateus/deborah_woll_224,rumateus/dua_lipa_224,rumateus/emma_stone_224,rumateus/hailee_steinfeld_224,rumateus/hilary_duff_224,rumateus/jessica_alba_224,rumateus/jessica_biel_224,rumateus/john_cena_224,rumateus/kim_kardashian_224,rumateus/kristen_bell_224,rumateus/lucy_liu_224,rumateus/margot_robbie_224,rumateus/megan_fox_224,rumateus/meghan_markle_224,rumateus/millie_bobby_brown_224,rumateus/natalie_portman_224,rumateus/nicki_minaj_224,rumateus/olivia_wilde_224,rumateus/shay_mitchell_224,rumateus/sophie_turner_224,rumateus/taylor_swift_224}]
                         [--deep-swapper-morph [0..100:1]]
                         [--expression-restorer-model {live_portrait}]
                         [--expression-restorer-factor [0..100:1]]
                         [--expression-restorer-areas EXPRESSION_RESTORER_AREAS [EXPRESSION_RESTORER_AREAS ...]]
                         [--face-debugger-items FACE_DEBUGGER_ITEMS [FACE_DEBUGGER_ITEMS ...]]
                         [--face-editor-model {live_portrait}]
                         [--face-editor-eyebrow-direction [-1.0..1.0:0.05]]
                         [--face-editor-eye-gaze-horizontal [-1.0..1.0:0.05]]
                         [--face-editor-eye-gaze-vertical [-1.0..1.0:0.05]]
                         [--face-editor-eye-open-ratio [-1.0..1.0:0.05]]
                         [--face-editor-lip-open-ratio [-1.0..1.0:0.05]]
                         [--face-editor-mouth-grim [-1.0..1.0:0.05]]
                         [--face-editor-mouth-pout [-1.0..1.0:0.05]]
                         [--face-editor-mouth-purse [-1.0..1.0:0.05]]
                         [--face-editor-mouth-smile [-1.0..1.0:0.05]]
                         [--face-editor-mouth-position-horizontal [-1.0..1.0:0.05]]
                         [--face-editor-mouth-position-vertical [-1.0..1.0:0.05]]
                         [--face-editor-head-pitch [-1.0..1.0:0.05]]
                         [--face-editor-head-yaw [-1.0..1.0:0.05]]
                         [--face-editor-head-roll [-1.0..1.0:0.05]]
                         [--face-enhancer-model {codeformer,gfpgan_1.2,gfpgan_1.3,gfpgan_1.4,gpen_bfr_256,gpen_bfr_512,gpen_bfr_1024,gpen_bfr_2048,restoreformer_plus_plus}]
                         [--face-enhancer-blend [0..100:1]]
                         [--face-enhancer-weight [0.0..1.0:0.05]]
                         [--face-swapper-model {blendswap_256,ghost_1_256,ghost_2_256,ghost_3_256,hififace_unofficial_256,hyperswap_1a_256,hyperswap_1b_256,hyperswap_1c_256,inswapper_128,inswapper_128_fp16,simswap_256,simswap_unofficial_512,uniface_256}]
                         [--face-swapper-pixel-boost {256x256,512x512,768x768,1024x1024}]
                         [--face-swapper-weight {0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0}]
                         [--frame-colorizer-model {ddcolor,ddcolor_artistic,deoldify,deoldify_artistic,deoldify_stable}]
                         [--frame-colorizer-size {192x192,256x256,384x384,512x512}]
                         [--frame-colorizer-blend [0..100:1]]
                         [--frame-enhancer-model {clear_reality_x4,face_dat_x4,lsdir_x4,nomos8k_sc_x4,real_esrgan_x2,real_esrgan_x2_fp16,real_esrgan_x4,real_esrgan_x4_fp16,real_esrgan_x8,real_esrgan_x8_fp16,real_hatgan_x4,real_web_photo_x4,realistic_rescaler_x4,remacri_x4,siax_x4,span_kendata_x4,swin2_sr_x4,tghq_face_x8,ultra_sharp_x4,ultra_sharp_2_x4}]
                         [--frame-enhancer-blend [0..100:1]]
                         [--lip-syncer-model {edtalk_256,wav2lip_96,wav2lip_gan_96}]
                         [--lip-syncer-weight [0.0..1.0:0.05]]
                         [--open-browser]
                         [--ui-layouts UI_LAYOUTS [UI_LAYOUTS ...]]
                         [--ui-workflow {instant_runner,job_runner,job_manager}]
                         [--benchmark-mode {warm,cold}]
                         [--benchmark-resolutions {240p,360p,540p,720p,1080p,1440p,2160p} [{240p,360p,540p,720p,1080p,1440p,2160p} ...]]
                         [--benchmark-cycle-count {1,2,3,4,5,6,7,8,9,10}]
                         [--execution-device-ids EXECUTION_DEVICE_IDS [EXECUTION_DEVICE_IDS ...]]
                         [--execution-providers EXECUTION_PROVIDERS [EXECUTION_PROVIDERS ...]]
                         [--execution-thread-count [1..32:1]]
                         [--download-providers DOWNLOAD_PROVIDERS [DOWNLOAD_PROVIDERS ...]]
                         [--video-memory-strategy {strict,moderate,tolerant}]
                         [--system-memory-limit [0..128:4]]
                         [--log-level {error,warn,info,debug}] [--modal]

options:
  -h, --help                                              show this help
                                                          message and exit

paths:
  --config-path CONFIG_PATH                               choose the config
                                                          file to override
                                                          defaults
  --temp-path TEMP_PATH                                   specify the
                                                          directory for the
                                                          temporary resources
  --jobs-path JOBS_PATH                                   specify the
                                                          directory to store
                                                          jobs
  -s SOURCE_PATHS [SOURCE_PATHS ...], --source-paths SOURCE_PATHS [SOURCE_PATHS ...]
                                                          choose the image or
                                                          audio paths
  -t TARGET_PATH, --target-path TARGET_PATH               choose the image or
                                                          video path
  -o OUTPUT_PATH, --output-path OUTPUT_PATH               specify the image or
                                                          video within a
                                                          directory

face detector:
  --face-detector-model {many,retinaface,scrfd,yolo_face,yunet}
                                                          choose the model
                                                          responsible for
                                                          detecting the faces
  --face-detector-size {640x640}                          specify the frame
                                                          size provided to the
                                                          face detector
  --face-detector-margin FACE_DETECTOR_MARGIN [FACE_DETECTOR_MARGIN ...]
                                                          apply top, right,
                                                          bottom and left
                                                          margin to the frame
  --face-detector-angles FACE_DETECTOR_ANGLES [FACE_DETECTOR_ANGLES ...]
                                                          specify the angles
                                                          to rotate the frame
                                                          before detecting
                                                          faces
  --face-detector-score [0.0..1.0:0.05]                   filter the detected
                                                          faces based on the
                                                          confidence score

face landmarker:
  --face-landmarker-model {many,2dfan4,peppa_wutz}        choose the model
                                                          responsible for
                                                          detecting the face
                                                          landmarks
  --face-landmarker-score [0.0..1.0:0.05]                 filter the detected
                                                          face landmarks based
                                                          on the confidence
                                                          score

face selector:
  --face-selector-mode {many,one,reference}               use reference based
                                                          tracking or simple
                                                          matching
  --face-selector-order {left-right,right-left,top-bottom,bottom-top,small-large,large-small,best-worst,worst-best}
                                                          specify the order of
                                                          the detected faces
  --face-selector-age-start [0..100:1]                    filter the detected
                                                          faces based on the
                                                          starting age
  --face-selector-age-end [0..100:1]                      filter the detected
                                                          faces based on the
                                                          ending age
  --face-selector-gender {female,male}                    filter the detected
                                                          faces based on their
                                                          gender
  --face-selector-race {white,black,latino,asian,indian,arabic}
                                                          filter the detected
                                                          faces based on their
                                                          race
  --reference-face-position REFERENCE_FACE_POSITION       specify the position
                                                          used to create the
                                                          reference face
  --reference-face-distance [0.0..1.0:0.05]               specify the
                                                          similarity between
                                                          the reference face
                                                          and target face
  --reference-frame-number REFERENCE_FRAME_NUMBER         specify the frame
                                                          used to create the
                                                          reference face

face masker:
  --face-occluder-model {many,xseg_1,xseg_2,xseg_3}       choose the model
                                                          responsible for the
                                                          occlusion mask
  --face-parser-model {bisenet_resnet_18,bisenet_resnet_34}
                                                          choose the model
                                                          responsible for the
                                                          region mask
  --face-mask-types FACE_MASK_TYPES [FACE_MASK_TYPES ...]
                                                          mix and match
                                                          different face mask
                                                          types (choices: box,
                                                          occlusion, area,
                                                          region)
  --face-mask-areas FACE_MASK_AREAS [FACE_MASK_AREAS ...]
                                                          choose the items
                                                          used for the area
                                                          mask (choices:
                                                          upper-face, lower-
                                                          face, mouth)
  --face-mask-regions FACE_MASK_REGIONS [FACE_MASK_REGIONS ...]
                                                          choose the items
                                                          used for the region
                                                          mask (choices: skin,
                                                          left-eyebrow, right-
                                                          eyebrow, left-eye,
                                                          right-eye, glasses,
                                                          nose, mouth, upper-
                                                          lip, lower-lip)
  --face-mask-blur [0.0..1.0:0.05]                        specify the degree
                                                          of blur applied to
                                                          the box mask
  --face-mask-padding FACE_MASK_PADDING [FACE_MASK_PADDING ...]
                                                          apply top, right,
                                                          bottom and left
                                                          padding to the box
                                                          mask

voice extractor:
  --voice-extractor-model {kim_vocal_1,kim_vocal_2,uvr_mdxnet}
                                                          choose the model
                                                          responsible for
                                                          extracting the
                                                          voices

frame extraction:
  --trim-frame-start TRIM_FRAME_START                     specify the starting
                                                          frame of the target
                                                          video
  --trim-frame-end TRIM_FRAME_END                         specify the ending
                                                          frame of the target
                                                          video
  --temp-frame-format {bmp,jpeg,png,tiff}                 specify the
                                                          temporary resources
                                                          format
  --keep-temp                                             keep the temporary
                                                          resources after
                                                          processing

output creation:
  --output-image-quality [0..100:1]                       specify the image
                                                          quality which
                                                          translates to the
                                                          image compression
  --output-image-scale {0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,2.25,2.5,2.75,3.0,3.25,3.5,3.75,4.0,4.25,4.5,4.75,5.0,5.25,5.5,5.75,6.0,6.25,6.5,6.75,7.0,7.25,7.5,7.75,8.0}
                                                          specify the image
                                                          scale based on the
                                                          target image
  --output-audio-encoder {flac,aac,libmp3lame,libopus,libvorbis,pcm_s16le,pcm_s32le}
                                                          specify the encoder
                                                          used for the audio
  --output-audio-quality [0..100:1]                       specify the audio
                                                          quality which
                                                          translates to the
                                                          audio compression
  --output-audio-volume [0..100:1]                        specify the audio
                                                          volume based on the
                                                          target video
  --output-video-encoder {libx264,libx264rgb,libx265,libvpx-vp9,h264_amf,h264_nvenc,hevc_nvenc,h264_qsv,hevc_amf,hevc_qsv,rawvideo}
                                                          specify the encoder
                                                          used for the video
  --output-video-preset {ultrafast,superfast,veryfast,faster,fast,medium,slow,slower,veryslow}
                                                          balance fast video
                                                          processing and video
                                                          file size
  --output-video-quality [0..100:1]                       specify the video
                                                          quality which
                                                          translates to the
                                                          video compression
  --output-video-scale {0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,2.25,2.5,2.75,3.0,3.25,3.5,3.75,4.0,4.25,4.5,4.75,5.0,5.25,5.5,5.75,6.0,6.25,6.5,6.75,7.0,7.25,7.5,7.75,8.0}
                                                          specify the video
                                                          scale based on the
                                                          target video
  --output-video-fps OUTPUT_VIDEO_FPS                     specify the video
                                                          fps based on the
                                                          target video

processors:
  --processors PROCESSORS [PROCESSORS ...]                load a single or
                                                          multiple processors
                                                          (choices:
                                                          age_modifier,
                                                          background_remover,
                                                          deep_swapper,
                                                          expression_restorer,
                                                          face_debugger,
                                                          face_editor,
                                                          face_enhancer,
                                                          face_swapper,
                                                          frame_colorizer,
                                                          frame_enhancer,
                                                          lip_syncer, ...)
  --age-modifier-model {styleganex_age}                   choose the model
                                                          responsible for
                                                          aging the face
  --age-modifier-direction [-100..100:1]                  specify the
                                                          direction in which
                                                          the age should be
                                                          modified
  --background-remover-model {ben_2,birefnet_general,birefnet_portrait,isnet_general,modnet,ormbg,rmbg_1.4,rmbg_2.0,silueta,u2net_cloth,u2net_general,u2net_human,u2netp}
                                                          choose the model
                                                          responsible for
                                                          removing the
                                                          background
  --background-remover-color BACKGROUND_REMOVER_COLOR [BACKGROUND_REMOVER_COLOR ...]
                                                          apply red, green
                                                          blue and alpha
                                                          values to the
                                                          background
  --deep-swapper-model {druuzil/adam_levine_320,druuzil/adrianne_palicki_384,druuzil/agnetha_falskog_224,druuzil/alan_ritchson_320,druuzil/alicia_vikander_320,druuzil/amber_midthunder_320,druuzil/andras_arato_384,druuzil/andrew_tate_320,druuzil/angelina_jolie_384,druuzil/anne_hathaway_320,druuzil/anya_chalotra_320,druuzil/arnold_schwarzenegger_320,druuzil/benjamin_affleck_320,druuzil/benjamin_stiller_384,druuzil/bradley_pitt_224,druuzil/brie_larson_384,druuzil/bruce_campbell_384,druuzil/bryan_cranston_320,druuzil/catherine_blanchett_352,druuzil/christian_bale_320,druuzil/christopher_hemsworth_320,druuzil/christoph_waltz_384,druuzil/cillian_murphy_320,druuzil/cobie_smulders_256,druuzil/dwayne_johnson_384,druuzil/edward_norton_320,druuzil/elisabeth_shue_320,druuzil/elizabeth_olsen_384,druuzil/elon_musk_320,druuzil/emily_blunt_320,druuzil/emma_stone_384,druuzil/emma_watson_320,druuzil/erin_moriarty_384,druuzil/eva_green_320,druuzil/ewan_mcgregor_320,druuzil/florence_pugh_320,druuzil/freya_allan_320,druuzil/gary_cole_224,druuzil/gigi_hadid_224,druuzil/harrison_ford_384,druuzil/hayden_christensen_320,druuzil/heath_ledger_320,druuzil/henry_cavill_448,druuzil/hugh_jackman_384,druuzil/idris_elba_320,druuzil/jack_nicholson_320,druuzil/james_carrey_384,druuzil/james_mcavoy_320,druuzil/james_varney_320,druuzil/jason_momoa_320,druuzil/jason_statham_320,druuzil/jennifer_connelly_384,druuzil/jimmy_donaldson_320,druuzil/jordan_peterson_384,druuzil/karl_urban_224,druuzil/kate_beckinsale_384,druuzil/laurence_fishburne_384,druuzil/lili_reinhart_320,druuzil/luke_evans_384,druuzil/mads_mikkelsen_384,druuzil/mary_winstead_320,druuzil/margaret_qualley_384,druuzil/melina_juergens_320,druuzil/michael_fassbender_320,druuzil/michael_fox_320,druuzil/millie_bobby_brown_320,druuzil/morgan_freeman_320,druuzil/patrick_stewart_224,druuzil/rachel_weisz_384,druuzil/rebecca_ferguson_320,druuzil/scarlett_johansson_320,druuzil/shannen_doherty_384,druuzil/seth_macfarlane_384,druuzil/thomas_cruise_320,druuzil/thomas_hanks_384,druuzil/william_murray_384,druuzil/zoe_saldana_384,edel/emma_roberts_224,edel/ivanka_trump_224,edel/lize_dzjabrailova_224,edel/sidney_sweeney_224,edel/winona_ryder_224,iperov/alexandra_daddario_224,iperov/alexei_navalny_224,iperov/amber_heard_224,iperov/dilraba_dilmurat_224,iperov/elon_musk_224,iperov/emilia_clarke_224,iperov/emma_watson_224,iperov/erin_moriarty_224,iperov/jackie_chan_224,iperov/james_carrey_224,iperov/jason_statham_320,iperov/keanu_reeves_320,iperov/margot_robbie_224,iperov/natalie_dormer_224,iperov/nicolas_coppola_224,iperov/robert_downey_224,iperov/rowan_atkinson_224,iperov/ryan_reynolds_224,iperov/scarlett_johansson_224,iperov/sylvester_stallone_224,iperov/thomas_cruise_224,iperov/thomas_holland_224,iperov/vin_diesel_224,iperov/vladimir_putin_224,jen/angelica_trae_288,jen/ella_freya_224,jen/emma_myers_320,jen/evie_pickerill_224,jen/kang_hyewon_320,jen/maddie_mead_224,jen/nicole_turnbull_288,mats/alica_schmidt_320,mats/ashley_alexiss_224,mats/billie_eilish_224,mats/brie_larson_224,mats/cara_delevingne_224,mats/carolin_kebekus_224,mats/chelsea_clinton_224,mats/claire_boucher_224,mats/corinna_kopf_224,mats/florence_pugh_224,mats/hillary_clinton_224,mats/jenna_fischer_224,mats/kim_jisoo_320,mats/mica_suarez_320,mats/shailene_woodley_224,mats/shraddha_kapoor_320,mats/yu_jimin_352,rumateus/alison_brie_224,rumateus/amber_heard_224,rumateus/angelina_jolie_224,rumateus/aubrey_plaza_224,rumateus/bridget_regan_224,rumateus/cobie_smulders_224,rumateus/deborah_woll_224,rumateus/dua_lipa_224,rumateus/emma_stone_224,rumateus/hailee_steinfeld_224,rumateus/hilary_duff_224,rumateus/jessica_alba_224,rumateus/jessica_biel_224,rumateus/john_cena_224,rumateus/kim_kardashian_224,rumateus/kristen_bell_224,rumateus/lucy_liu_224,rumateus/margot_robbie_224,rumateus/megan_fox_224,rumateus/meghan_markle_224,rumateus/millie_bobby_brown_224,rumateus/natalie_portman_224,rumateus/nicki_minaj_224,rumateus/olivia_wilde_224,rumateus/shay_mitchell_224,rumateus/sophie_turner_224,rumateus/taylor_swift_224}
                                                          choose the model
                                                          responsible for
                                                          swapping the face
  --deep-swapper-morph [0..100:1]                         morph between source
                                                          face and target
                                                          faces
  --expression-restorer-model {live_portrait}             choose the model
                                                          responsible for
                                                          restoring the
                                                          expression
  --expression-restorer-factor [0..100:1]                 restore factor of
                                                          expression from the
                                                          target face
  --expression-restorer-areas EXPRESSION_RESTORER_AREAS [EXPRESSION_RESTORER_AREAS ...]
                                                          choose the items
                                                          used for the
                                                          expression areas
                                                          (choices: upper-
                                                          face, lower-face)
  --face-debugger-items FACE_DEBUGGER_ITEMS [FACE_DEBUGGER_ITEMS ...]
                                                          load a single or
                                                          multiple processors
                                                          (choices: bounding-
                                                          box, face-
                                                          landmark-5, face-
                                                          landmark-5/68, face-
                                                          landmark-68, face-
                                                          landmark-68/5, face-
                                                          mask)
  --face-editor-model {live_portrait}                     choose the model
                                                          responsible for
                                                          editing the face
  --face-editor-eyebrow-direction [-1.0..1.0:0.05]        specify the eyebrow
                                                          direction
  --face-editor-eye-gaze-horizontal [-1.0..1.0:0.05]      specify the
                                                          horizontal eye gaze
  --face-editor-eye-gaze-vertical [-1.0..1.0:0.05]        specify the vertical
                                                          eye gaze
  --face-editor-eye-open-ratio [-1.0..1.0:0.05]           specify the ratio of
                                                          eye opening
  --face-editor-lip-open-ratio [-1.0..1.0:0.05]           specify the ratio of
                                                          lip opening
  --face-editor-mouth-grim [-1.0..1.0:0.05]               specify the mouth
                                                          grim
  --face-editor-mouth-pout [-1.0..1.0:0.05]               specify the mouth
                                                          pout
  --face-editor-mouth-purse [-1.0..1.0:0.05]              specify the mouth
                                                          purse
  --face-editor-mouth-smile [-1.0..1.0:0.05]              specify the mouth
                                                          smile
  --face-editor-mouth-position-horizontal [-1.0..1.0:0.05]
                                                          specify the
                                                          horizontal mouth
                                                          position
  --face-editor-mouth-position-vertical [-1.0..1.0:0.05]  specify the vertical
                                                          mouth position
  --face-editor-head-pitch [-1.0..1.0:0.05]               specify the head
                                                          pitch
  --face-editor-head-yaw [-1.0..1.0:0.05]                 specify the head yaw
  --face-editor-head-roll [-1.0..1.0:0.05]                specify the head
                                                          roll
  --face-enhancer-model {codeformer,gfpgan_1.2,gfpgan_1.3,gfpgan_1.4,gpen_bfr_256,gpen_bfr_512,gpen_bfr_1024,gpen_bfr_2048,restoreformer_plus_plus}
                                                          choose the model
                                                          responsible for
                                                          enhancing the face
  --face-enhancer-blend [0..100:1]                        blend the enhanced
                                                          into the previous
                                                          face
  --face-enhancer-weight [0.0..1.0:0.05]                  specify the degree
                                                          of weight applied to
                                                          the face
  --face-swapper-model {blendswap_256,ghost_1_256,ghost_2_256,ghost_3_256,hififace_unofficial_256,hyperswap_1a_256,hyperswap_1b_256,hyperswap_1c_256,inswapper_128,inswapper_128_fp16,simswap_256,simswap_unofficial_512,uniface_256}
                                                          choose the model
                                                          responsible for
                                                          swapping the face
  --face-swapper-pixel-boost {256x256,512x512,768x768,1024x1024}
                                                          choose the pixel
                                                          boost resolution for
                                                          the face swapper
  --face-swapper-weight {0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0}
                                                          specify the degree
                                                          of weight applied to
                                                          the face
  --frame-colorizer-model {ddcolor,ddcolor_artistic,deoldify,deoldify_artistic,deoldify_stable}
                                                          choose the model
                                                          responsible for
                                                          colorizing the frame
  --frame-colorizer-size {192x192,256x256,384x384,512x512}
                                                          specify the frame
                                                          size provided to the
                                                          frame colorizer
  --frame-colorizer-blend [0..100:1]                      blend the colorized
                                                          into the previous
                                                          frame
  --frame-enhancer-model {clear_reality_x4,face_dat_x4,lsdir_x4,nomos8k_sc_x4,real_esrgan_x2,real_esrgan_x2_fp16,real_esrgan_x4,real_esrgan_x4_fp16,real_esrgan_x8,real_esrgan_x8_fp16,real_hatgan_x4,real_web_photo_x4,realistic_rescaler_x4,remacri_x4,siax_x4,span_kendata_x4,swin2_sr_x4,tghq_face_x8,ultra_sharp_x4,ultra_sharp_2_x4}
                                                          choose the model
                                                          responsible for
                                                          enhancing the frame
  --frame-enhancer-blend [0..100:1]                       blend the enhanced
                                                          into the previous
                                                          frame
  --lip-syncer-model {edtalk_256,wav2lip_96,wav2lip_gan_96}
                                                          choose the model
                                                          responsible for
                                                          syncing the lips
  --lip-syncer-weight [0.0..1.0:0.05]                     specify the degree
                                                          of weight applied to
                                                          the lips

uis:
  --open-browser                                          open the browser
                                                          once the program is
                                                          ready
  --ui-layouts UI_LAYOUTS [UI_LAYOUTS ...]                launch a single or
                                                          multiple UI layouts
                                                          (choices: benchmark,
                                                          default, jobs,
                                                          simple, webcam, ...)
  --ui-workflow {instant_runner,job_runner,job_manager}   choose the ui
                                                          workflow

benchmark:
  --benchmark-mode {warm,cold}                            choose the benchmark
                                                          mode
  --benchmark-resolutions {240p,360p,540p,720p,1080p,1440p,2160p} [{240p,360p,540p,720p,1080p,1440p,2160p} ...]
                                                          choose the
                                                          resolutions for the
                                                          benchmarks (choices:
                                                          {choices}, ...)
  --benchmark-cycle-count {1,2,3,4,5,6,7,8,9,10}          specify the amount
                                                          of cycles per
                                                          benchmark

execution:
  --execution-device-ids EXECUTION_DEVICE_IDS [EXECUTION_DEVICE_IDS ...]
                                                          specify the devices
                                                          used for processing
  --execution-providers EXECUTION_PROVIDERS [EXECUTION_PROVIDERS ...]
                                                          inference using
                                                          different providers
                                                          (choices: cpu, ...)
  --execution-thread-count [1..32:1]                      specify the amount
                                                          of parallel threads
                                                          while processing

download:
  --download-providers DOWNLOAD_PROVIDERS [DOWNLOAD_PROVIDERS ...]
                                                          download using
                                                          different providers
                                                          (choices: github,
                                                          huggingface, ...)

memory:
  --video-memory-strategy {strict,moderate,tolerant}      balance fast
                                                          processing and low
                                                          VRAM usage
  --system-memory-limit [0..128:4]                        limit the available
                                                          RAM that can be used
                                                          while processing

misc:
  --log-level {error,warn,info,debug}                     adjust the message
                                                          severity displayed
                                                          in the terminal
  --modal                                                 run the program
                                                          using modal.com
